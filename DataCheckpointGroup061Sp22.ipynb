{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Arnav Tayal\n",
    "- Chaewon Heo\n",
    "- Martha Chow\n",
    "- Zhiyi Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main question: Are characteristics of an individual’s diet (such as the amount of calories, macronutrients, and/or micronutrients) correlated with their likelihood of contracting COVID-19?\n",
    "\n",
    "Sub-questions: Can we correlate diet type (eg. vegetarian, keto, pescetarian) with an individual’s likelihood of contracting COVID-19? Which characteristic is the strongest predictor?\n",
    "\n",
    "Potential extension: Does correlation between a characteristic necessarily mean causation (eg. If we find that there is a positive correlation between kcal/day and likelihood of contracting COVID-19, does that necessarily mean that a high calorie diet leads to higher vulnerability to COVID-19?)? How much literature is there on databases to support the causal relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Dataset Name: Supply_Quantity_Kg\n",
    "- Link to the dataset:https://github.com/mariarencode/COVID_19_Dataset_Challenge/tree/master/Food_Supply_Quantity_Kg\n",
    "- Number of observations: 174\n",
    "\n",
    "Each file in this dataset records the amount of a particular food category of each country in kilograms/capita/yr\n",
    "\n",
    "- Dataset Name: Fat Supply\n",
    "- Link to the dataset: https://github.com/mariarencode/COVID_19_Dataset_Challenge/tree/master/Fat_Supply\n",
    "- Number of observations: 174\n",
    "\n",
    "Each file in this dataset records the amount of fat in a particular food category of each country in grams/capita/yr\n",
    "\n",
    "- Dataset Name: Protein Supply\n",
    "- Link to the dataset: https://github.com/mariarencode/COVID_19_Dataset_Challenge/tree/master/Protein_Supply\n",
    "- Number of observations: 174\n",
    "\n",
    "Each file in this dataset records the amount of protein in a particular food category of each country in grams/capita/yr\n",
    "\n",
    "We plan to pick particular columns from these datasets and combine them using the merge function in pandas, each row will be unique to a country "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# packages for importing files\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get the add the Confirmed,Deaths,Recovered,Active,Population to the dataframe; those are directly extracted from the dataframe that records the precentages. Beside the population, the unit for the other 4 quantitative columns are in percentages.__\n",
    "\n",
    "NOTE: the cleaned data (the percentages) from github is somehow different from the ones on kaggle. Which one do we want to use for the rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = pd.read_csv(\"/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Cleaned_Datasets/Food_Supply_Quantity_kg_Data.csv\",usecols=['Country','Confirmed','Deaths','Recovered','Active','Population'])\n",
    "df_covid.columns = (map(lambda x: x.lower(), df_covid.columns))\n",
    "df_covid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Process data for food quantity (unit: kg/capita/yr)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most csvs as a list\n",
    "path = '/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Food_Supply_Quantity_Kg' # TODO: change this to the path that contains Food_Supply_Quantity_Kg on your enviroment\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that standardize food name; all lowercase + no space + no special character\n",
    "def getName(n):\n",
    "    name = n.replace(' ','_')\n",
    "    name = name.replace('-','')\n",
    "    name = name.replace(',','')\n",
    "    name = name.replace('&','')\n",
    "    name = name.replace('__','_')\n",
    "    return name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the first csv in the directory so we can merge other csvs with it\n",
    "col_list = [\"Area\", \"Item\", \"Value\"] # we only need the country and the quantity of food from the file\n",
    "df_quantity = pd.read_csv(all_files[0], usecols=col_list)\n",
    "name = getName(df_quantity.loc[0].at[\"Item\"])\n",
    "df_quantity = df_quantity.drop('Item', 1)\n",
    "df_quantity.columns = ['country',name]\n",
    "\n",
    "# merge all csvs in the directory into df_quantity\n",
    "for i in all_files[1:len(all_files)]:\n",
    "    # extract the name of the file\n",
    "    tmp = pd.read_csv(i, usecols=col_list)\n",
    "    name = getName(tmp.loc[0].at[\"Item\"])\n",
    "    tmp = tmp.drop('Item', 1)\n",
    "    tmp.columns = ['country',name] \n",
    "    df_quantity = pd.merge(df_quantity,tmp,on ='country', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need the Animal Product and Vegetal Product csvs that are in different forms, so add them to dataframe seperately\n",
    "animal = pd.read_csv(\"/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Unprocessed_Data/FAOSTAT_food_kg_animal.csv\") #TODO: change this to the unprocess data directory in your enviroment\n",
    "animal.columns = ['country','animal_products'] \n",
    "vegetal_prod = pd.read_csv(\"/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Unprocessed_Data/FAOSTAT_food_kg_vegetal_prod.csv\") #TODO: change this to the unprocess data directory in your enviroment\n",
    "vegetal_prod.columns = ['country','vegetal_products']\n",
    "df_quantity = pd.merge(df_quantity,animal,on ='country', how='outer')\n",
    "df_quantity = pd.merge(df_quantity,vegetal_prod,on ='country', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the columns, with country at the first column, and the food columns in alphabetical order\n",
    "df_quantity = df_quantity.sort_index(axis=1)\n",
    "first_column = df_quantity.pop('country')\n",
    "df_quantity.insert(0, 'country', first_column)\n",
    "\n",
    "# fill na with 0\n",
    "df_quantity = df_quantity.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine with total quantity dataframe with the covid dataframe\n",
    "# TODO: if we want the df_covid to be a seperate dataframe, just delete this cell.\n",
    "df_quantity = pd.merge(df_quantity,df_covid,on ='country', how='right') # join on right since the covid rates are essential for further analysis, so we don't want NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantity.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Process data for fat ( original unit: g/capita/day; will be converted to kg/capita/year)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts g/capita/day to kg/capita/yr \n",
    "# TODO: someone check if this is correct\n",
    "def standUnit(x):\n",
    "    # g -> kg: / 1000\n",
    "    # day -> year: * 365\n",
    "    return x / 1000 * 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most csvs as a list\n",
    "path = '/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Fat_Supply' # TODO: change this to the path that contains Food_Supply_Quantity_Kg on your enviroment\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# read in the first csv in the directory so we can merge other csvs with it\n",
    "col_list = [\"Area\", \"Item\", \"Value\"] # we only need the country and the quantity of food from the file\n",
    "df_fat = pd.read_csv(all_files[0], usecols=col_list)\n",
    "name = getName(df_fat.loc[0].at[\"Item\"])\n",
    "df_fat = df_fat.drop('Item', 1)\n",
    "df_fat.columns = ['country',name]\n",
    "\n",
    "# merge all csvs in the directory into df_fat\n",
    "for i in all_files[1:len(all_files)]:\n",
    "    # extract the name of the file\n",
    "    tmp = pd.read_csv(i, usecols=col_list)\n",
    "    name = getName(tmp.loc[0].at[\"Item\"])\n",
    "    tmp = tmp.drop('Item', 1)\n",
    "    tmp.columns = ['country',name] \n",
    "    df_fat = pd.merge(df_fat,tmp,on ='country', how='outer')\n",
    "    \n",
    "# sort the columns, with country at the first column, and the food columns in alphabetical order\n",
    "df_fat = df_fat.sort_index(axis=1)\n",
    "first_column = df_fat.pop('country')\n",
    "df_fat.insert(0, 'country', first_column)\n",
    "\n",
    "# replace na with 0\n",
    "df_fat = df_fat.fillna(0)\n",
    "df_fat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert g/capita/day to kg/capita/yr\n",
    "df_fat[df_fat.columns[1:len(df_fat.columns)]] = df_fat[df_fat.columns[1:len(df_fat.columns)]].applymap(standUnit)\n",
    "df_fat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fat = pd.merge(df_fat,df_covid,on ='country', how='right') # join on right since the covid rates are essential for further analysis, so we don't want NA in the covid rates column\n",
    "df_fat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Process protein as fat__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most csvs as a list\n",
    "path = '/cellar/users/zhzhu/projects/random/COGS108/COVID_19_Dataset_Challenge/Protein_Supply' # TODO: change this to the path that contains Food_Supply_Quantity_Kg on your enviroment\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# read in the first csv in the directory so we can merge other csvs with it\n",
    "col_list = [\"Area\", \"Item\", \"Value\"] # we only need the country and the quantity of food from the file\n",
    "df_protein = pd.read_csv(all_files[0], usecols=col_list)\n",
    "name = getName(df_protein.loc[0].at[\"Item\"])\n",
    "df_protein = df_protein.drop('Item', 1)\n",
    "df_protein.columns = ['country',name]\n",
    "\n",
    "# merge all csvs in the directory into df_protein\n",
    "for i in all_files[1:len(all_files)]:\n",
    "    # extract the name of the file\n",
    "    tmp = pd.read_csv(i, usecols=col_list)\n",
    "    name = getName(tmp.loc[0].at[\"Item\"])\n",
    "    tmp = tmp.drop('Item', 1)\n",
    "    tmp.columns = ['country',name] \n",
    "    df_protein = pd.merge(df_protein,tmp,on ='country', how='outer')\n",
    "    \n",
    "# sort the columns, with country at the first column, and the food columns in alphabetical order\n",
    "df_protein = df_protein.sort_index(axis=1)\n",
    "first_column = df_protein.pop('country')\n",
    "df_protein.insert(0, 'country', first_column)\n",
    "\n",
    "# replace na with 0\n",
    "df_protein = df_protein.fillna(0)\n",
    "df_protein.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert g/capita/day to kg/capita/yr\n",
    "df_protein[df_protein.columns[1:len(df_protein.columns)]] = df_protein[df_protein.columns[1:len(df_protein.columns)]].applymap(standUnit)\n",
    "df_protein.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protein = pd.merge(df_protein,df_covid,on ='country', how='right') # join on right since the covid rates are essential for further analysis, so we don't want NA in the covid rates column\n",
    "df_protein.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
